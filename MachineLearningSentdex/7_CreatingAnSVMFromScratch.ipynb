{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('MLEnv': conda)"
  },
  "interpreter": {
   "hash": "08c69c18d40957683e009b324eccd50698d32a0e1363c2d903575727cdb7d6c7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib import style\r\n",
    "\r\n",
    "style.use('ggplot')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\r\n",
    "data_dict = {-1:np.array([[1,7],\r\n",
    "                          [2,8],\r\n",
    "                          [3,8],]),\r\n",
    "             \r\n",
    "             1:np.array([[5,1],\r\n",
    "                         [6,-1],\r\n",
    "                         [7,3],])}\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "predict_us = [[0,10],\r\n",
    "              [1,3],\r\n",
    "              [3,4],\r\n",
    "              [3,5],\r\n",
    "              [5,5],\r\n",
    "              [5,6],\r\n",
    "              [6,-5],\r\n",
    "              [5,8]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\r\n",
    "class Support_Vector_Machine:\r\n",
    "    def __init__(self, visualization=True):\r\n",
    "        self.visualization = visualization\r\n",
    "        self.colors = {1:'r',-1:'b'}\r\n",
    "        if self.visualization:\r\n",
    "            self.fig = plt.figure()\r\n",
    "            self.ax = self.fig.add_subplot(1,1,1)\r\n",
    "    # train\r\n",
    "    def fit(self, data):\r\n",
    "        self.data = data\r\n",
    "        # { ||w||: [w,b] }\r\n",
    "        opt_dict = {}\r\n",
    "\r\n",
    "        transforms = [[1,1],\r\n",
    "                      [-1,1],\r\n",
    "                      [-1,-1],\r\n",
    "                      [1,-1]]\r\n",
    "\r\n",
    "        all_data = []\r\n",
    "        for yi in self.data:\r\n",
    "            for featureset in self.data[yi]:\r\n",
    "                for feature in featureset:\r\n",
    "                    all_data.append(feature)\r\n",
    "\r\n",
    "        self.max_feature_value = max(all_data)\r\n",
    "        self.min_feature_value = min(all_data)\r\n",
    "        all_data = None\r\n",
    "\r\n",
    "        # support vectors yi(xi.w+b) = 1\r\n",
    "        \r\n",
    "\r\n",
    "        step_sizes = [self.max_feature_value * 0.1,\r\n",
    "                      self.max_feature_value * 0.01,\r\n",
    "                      # point of expense:\r\n",
    "                      self.max_feature_value * 0.001,\r\n",
    "                      ]\r\n",
    "\r\n",
    "        \r\n",
    "        \r\n",
    "        # extremely expensive\r\n",
    "        b_range_multiple = 2\r\n",
    "        # we dont need to take as small of steps\r\n",
    "        # with b as we do w\r\n",
    "        b_multiple = 5\r\n",
    "        latest_optimum = self.max_feature_value*10\r\n",
    "        \r\n",
    "        for step in step_sizes:\r\n",
    "            w = np.array([latest_optimum,latest_optimum])\r\n",
    "            # we can do this because convex\r\n",
    "            optimized = False\r\n",
    "            while not optimized:\r\n",
    "                for b in np.arange(-1*(self.max_feature_value*b_range_multiple),\r\n",
    "                                   self.max_feature_value*b_range_multiple,\r\n",
    "                                   step*b_multiple):\r\n",
    "                    for transformation in transforms:\r\n",
    "                        w_t = w*transformation\r\n",
    "                        found_option = True\r\n",
    "                        # weakest link in the SVM fundamentally\r\n",
    "                        # SMO attempts to fix this a bit\r\n",
    "                        # yi(xi.w+b) >= 1\r\n",
    "                        # \r\n",
    "                        # #### add a break here later..\r\n",
    "                        for i in self.data:\r\n",
    "                            for xi in self.data[i]:\r\n",
    "                                yi=i\r\n",
    "                                if not yi*(np.dot(w_t,xi)+b) >= 1:\r\n",
    "                                    found_option = False\r\n",
    "                                    #print(xi,':',yi*(np.dot(w_t,xi)+b))\r\n",
    "                                    \r\n",
    "                        if found_option:\r\n",
    "                            opt_dict[np.linalg.norm(w_t)] = [w_t,b]\r\n",
    "\r\n",
    "                if w[0] < 0:\r\n",
    "                    optimized = True\r\n",
    "                    print('Optimized a step.')\r\n",
    "                else:\r\n",
    "                    w = w - step\r\n",
    "\r\n",
    "            norms = sorted([n for n in opt_dict])\r\n",
    "            #||w|| : [w,b]\r\n",
    "            opt_choice = opt_dict[norms[0]]\r\n",
    "            self.w = opt_choice[0]\r\n",
    "            self.b = opt_choice[1]\r\n",
    "            latest_optimum = opt_choice[0][0]+step*2\r\n",
    "            \r\n",
    "        for i in self.data:\r\n",
    "            for xi in self.data[i]:\r\n",
    "                yi=i\r\n",
    "                print(xi,':',yi*(np.dot(self.w,xi)+self.b))            \r\n",
    "\r\n",
    "    def predict(self,features):\r\n",
    "        # sign( x.w+b )\r\n",
    "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\r\n",
    "        if classification !=0 and self.visualization:\r\n",
    "            self.ax.scatter(features[0], features[1], s=200, marker='*', c=self.colors[classification])\r\n",
    "        return classification\r\n",
    "\r\n",
    "    def visualize(self):\r\n",
    "        [[self.ax.scatter(x[0],x[1],s=100,color=self.colors[i]) for x in data_dict[i]] for i in data_dict]\r\n",
    "\r\n",
    "        # hyperplane = x.w+b\r\n",
    "        # v = x.w+b\r\n",
    "        # psv = 1\r\n",
    "        # nsv = -1\r\n",
    "        # dec = 0\r\n",
    "        def hyperplane(x,w,b,v):\r\n",
    "            return (-w[0]*x-b+v) / w[1]\r\n",
    "\r\n",
    "        datarange = (self.min_feature_value*0.9,self.max_feature_value*1.1)\r\n",
    "        hyp_x_min = datarange[0]\r\n",
    "        hyp_x_max = datarange[1]\r\n",
    "\r\n",
    "        # (w.x+b) = 1\r\n",
    "        # positive support vector hyperplane\r\n",
    "        psv1 = hyperplane(hyp_x_min, self.w, self.b, 1)\r\n",
    "        psv2 = hyperplane(hyp_x_max, self.w, self.b, 1)\r\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[psv1,psv2], 'k')\r\n",
    "\r\n",
    "        # (w.x+b) = -1\r\n",
    "        # negative support vector hyperplane\r\n",
    "        nsv1 = hyperplane(hyp_x_min, self.w, self.b, -1)\r\n",
    "        nsv2 = hyperplane(hyp_x_max, self.w, self.b, -1)\r\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[nsv1,nsv2], 'k')\r\n",
    "\r\n",
    "        # (w.x+b) = 0\r\n",
    "        # positive support vector hyperplane\r\n",
    "        db1 = hyperplane(hyp_x_min, self.w, self.b, 0)\r\n",
    "        db2 = hyperplane(hyp_x_max, self.w, self.b, 0)\r\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[db1,db2], 'y--')\r\n",
    "\r\n",
    "        plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "svm = Support_Vector_Machine()\r\n",
    "svm.fit(data=data_dict)\r\n",
    " \r\n",
    "for p in predict_us:\r\n",
    "    svm.predict(p)\r\n",
    "\r\n",
    "svm.visualize()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimized a step.\n",
      "Optimized a step.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "svm.predict([5, 2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "svm.predict([0, 2])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "svm.predict([5, 7])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}